{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #for accessing data from local directories\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated Transctions\n",
    "\n",
    "path1 = \"C:/Users/Srinivasa Rao/OneDrive/Documents/PhonePe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "aggre_trans_list = os.listdir(path1)\n",
    "\n",
    "columns = {'States':[], 'Years':[], 'Quartile':[], \n",
    "           'Transaction_type':[], 'Transaction_count':[], \n",
    "           'Transaction_amount':[] \n",
    "           }\n",
    "\n",
    "for state in aggre_trans_list:\n",
    "    curr_states = path1 + state + '/'\n",
    "    aggre_year_list = os.listdir(curr_states)\n",
    "    \n",
    "    for year in aggre_year_list:\n",
    "        curr_year = curr_states + year + \"/\"\n",
    "        aggre_file_list = os.listdir(curr_year)\n",
    "        \n",
    "        for file in aggre_file_list:\n",
    "            curr_file = curr_year + file\n",
    "            data = open(curr_file,'r')\n",
    "            \n",
    "            A = json.load(data)\n",
    "            \n",
    "            for i in A['data']['transactionData']:\n",
    "                name = i['name']\n",
    "                count = i['paymentInstruments'][0]['count']\n",
    "                amount = i['paymentInstruments'][0]['amount']\n",
    "                columns['Transaction_type'].append(name)\n",
    "                columns['Transaction_count'].append(count)\n",
    "                columns['Transaction_amount'].append(amount)\n",
    "                columns['States'].append(state)\n",
    "                columns['Years'].append(year)\n",
    "                columns['Quartile'].append(int(file.strip('.json')))\n",
    "\n",
    "aggre_transaction = pd.DataFrame(columns)\n",
    "\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('andhra-pradesh','andhra pradesh')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('west-bengal','west bengal')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('madhya-pradesh','madhya pradesh')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('jammu-&-kashmir','jammu & kashmir')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('himachal-pradesh','himachal pradesh')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace(\"arunachal-pradesh\",'arunachal pradesh')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('tamil-nadu','tamil nadu')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('uttar-pradesh','uttar pradesh')\n",
    "\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace('dadra-&-nagar-haveli-&-daman-&-diu','dadra and nagar haveli and daman and diu')\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.title()\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_user\n",
    "path2 = 'C:/Users/Srinivasa Rao/OneDrive/Documents/PhonePe/pulse/data/aggregated/user/country/india/state/'\n",
    "aggre_user_list = os.listdir(path2)\n",
    "\n",
    "\n",
    "columns1 = {'States':[], 'Years':[], 'Quartile':[], \n",
    "           'Brands':[], 'Transaction_count':[], \n",
    "           'Percentage':[] \n",
    "           }\n",
    "\n",
    "for state in aggre_user_list:\n",
    "    curr_states = path2 + state + '/'\n",
    "    aggre_year_list = os.listdir(curr_states)\n",
    "    \n",
    "    for year in aggre_year_list:\n",
    "        curr_year = curr_states + year + \"/\"\n",
    "        aggre_file_list = os.listdir(curr_year)\n",
    "        \n",
    "        for file in aggre_file_list:\n",
    "            curr_file = curr_year + file\n",
    "            data = open(curr_file,'r')\n",
    "            \n",
    "            B = json.load(data)\n",
    "            \n",
    "            try:\n",
    "                for i in B['data']['usersByDevice']:\n",
    "                    brand = i['brand']\n",
    "                    count = i['count']\n",
    "                    percentage = i['percentage']\n",
    "                    columns1['Brands'].append(brand)\n",
    "                    columns1['Transaction_count'].append(count)\n",
    "                    columns1['Percentage'].append(percentage)\n",
    "                    columns1['States'].append(state)\n",
    "                    columns1['Years'].append(year)\n",
    "                    columns1['Quartile'].append(int(file.strip('.json')))\n",
    "                    \n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "aggre_user = pd.DataFrame(columns1)\n",
    "\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('andhra-pradesh','andhra pradesh')\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('west-bengal','west bengal')\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('madhya-pradesh','madhya pradesh')\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('jammu-&-kashmir','jammu & kashmir')\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('himachal-pradesh','himachal pradesh')\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('arunachal-pradesh','arunachal pradesh')\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('uttar-pradesh','uttar pradesh')\n",
    "\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('tamil-nadu','tamil nadu')\n",
    "aggre_user['States'] = aggre_user['States'].str.replace('dadra-&-nagar-haveli-&-daman-&-diu','dadra and nagar haveli and daman and diu')\n",
    "aggre_user['States'] = aggre_user['States'].str.title()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "path3 = 'C:/Users/Srinivasa Rao/OneDrive/Documents/PhonePe/pulse/data/map/transaction/hover/country/india/state/'\n",
    "map_trans_list = os.listdir(path3)\n",
    "\n",
    "columns2 = {'States':[], 'Years':[], 'Quartile':[], \n",
    "           'Districts':[], 'Transaction_count':[], \n",
    "           'Transaction_amount':[] \n",
    "           }\n",
    "\n",
    "for state in map_trans_list:\n",
    "    curr_states = path3 + state + '/'\n",
    "    aggre_year_list = os.listdir(curr_states)\n",
    "    \n",
    "    for year in aggre_year_list:\n",
    "        curr_year = curr_states + year + \"/\"\n",
    "        aggre_file_list = os.listdir(curr_year)\n",
    "        \n",
    "        for file in aggre_file_list:\n",
    "            curr_file = curr_year + file\n",
    "            data = open(curr_file,'r')\n",
    "            \n",
    "            C = json.load(data)\n",
    "            \n",
    "            try:\n",
    "                for i in C['data']['hoverDataList']:\n",
    "                    name = i['name']\n",
    "                    count = i['metric'][0]['count']\n",
    "                    amount = i['metric'][0]['amount']\n",
    "                    columns2['Districts'].append(name)\n",
    "                    columns2['Transaction_count'].append(count)\n",
    "                    columns2['Transaction_amount'].append(amount)\n",
    "                    columns2['States'].append(state)\n",
    "                    columns2['Years'].append(year)\n",
    "                    columns2['Quartile'].append(int(file.strip('.json')))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_transactions = pd.DataFrame(columns2)\n",
    "\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('andhra-pradesh','andhra pradesh')\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('west-bengal','west bengal')\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('madhya-pradesh','madhya pradesh')\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('jammu-&-kashmir','jammu & kashmir')\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('himachal-pradesh','himachal pradesh')\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('arunachal-pradesh','arunachal pradesh')\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('tamil-nadu','tamil nadu')\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('uttar-pradesh','uttar pradesh')\n",
    "\n",
    "map_transactions['States'] = map_transactions['States'].str.replace('dadra-&-nagar-haveli-&-daman-&-diu','dadra and nagar haveli and daman and diu')\n",
    "map_transactions['States'] = map_transactions['States'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "path4 = 'C:/Users/Srinivasa Rao/OneDrive/Documents/PhonePe/pulse/data/map/user/hover/country/india/state/'\n",
    "map_user_list = os.listdir(path4)\n",
    "\n",
    "columns3 = {'States':[], 'Years':[], 'Quartile':[], \n",
    "           'Districts':[], 'RegisteredUsers':[], \n",
    "           'AppOpens':[] \n",
    "           }\n",
    "\n",
    "for state in map_user_list:\n",
    "    curr_states = path4 + state + '/'\n",
    "    map_year_list = os.listdir(curr_states)\n",
    "    \n",
    "    for year in aggre_year_list:\n",
    "        curr_year = curr_states + year + \"/\"\n",
    "        aggre_file_list = os.listdir(curr_year)\n",
    "        \n",
    "        for file in aggre_file_list:\n",
    "            curr_file = curr_year + file\n",
    "            data = open(curr_file,'r')\n",
    "            \n",
    "            D = json.load(data)\n",
    "            \n",
    "            \n",
    "            for i in D['data']['hoverData'].items():\n",
    "                district = i[0]\n",
    "                registeredusers = i[1]['registeredUsers']\n",
    "                appOpens = i[1]['appOpens']\n",
    "                columns3['Districts'].append(district)\n",
    "                columns3['RegisteredUsers'].append(registeredusers)\n",
    "                columns3['AppOpens'].append(appOpens)\n",
    "                columns3['States'].append(state)\n",
    "                columns3['Years'].append(year)\n",
    "                columns3['Quartile'].append(int(file.strip('.json')))\n",
    "\n",
    "map_user = pd.DataFrame(columns3)      \n",
    "\n",
    "map_user['States'] = map_user['States'].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "map_user['States'] = map_user['States'].str.replace('andhra-pradesh','andhra pradesh')\n",
    "map_user['States'] = map_user['States'].str.replace('west-bengal','west bengal')\n",
    "map_user['States'] = map_user['States'].str.replace('madhya-pradesh','madhya pradesh')\n",
    "map_user['States'] = map_user['States'].str.replace('jammu-&-kashmir','jammu & kashmir')\n",
    "map_user['States'] = map_user['States'].str.replace('himachal-pradesh','himachal pradesh')\n",
    "map_user['States'] = map_user['States'].str.replace('arunachal-pradesh','arunachal pradesh')\n",
    "map_user['States'] = map_user['States'].str.replace('uttar-pradesh','uttar pradesh')\n",
    "\n",
    "map_user['States'] = map_user['States'].str.replace('tamil-nadu','tamil nadu')\n",
    "map_user['States'] = map_user['States'].str.replace('dadra-&-nagar-haveli-&-daman-&-diu','dadra and nagar haveli and daman and diu')\n",
    "map_user['States'] = map_user['States'].str.title()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path5 = 'C:/Users/Srinivasa Rao/OneDrive/Documents/PhonePe/pulse/data/top/transaction/country/india/state/'\n",
    "top_trans_list = os.listdir(path5)\n",
    "\n",
    "columns4 = {'States':[], 'Years':[], 'Quartile':[], \n",
    "           'Pincodes':[], 'Transaction_count':[], \n",
    "           'Transaction_amount':[] \n",
    "           }\n",
    "\n",
    "for state in top_trans_list:\n",
    "    curr_states = path5 + state + '/'\n",
    "    aggre_year_list = os.listdir(curr_states)\n",
    "    \n",
    "    for year in aggre_year_list:\n",
    "        curr_year = curr_states + year + \"/\"\n",
    "        aggre_file_list = os.listdir(curr_year)\n",
    "        \n",
    "        for file in aggre_file_list:\n",
    "            curr_file = curr_year + file\n",
    "            data = open(curr_file,'r')\n",
    "            \n",
    "            E = json.load(data)\n",
    "            \n",
    "            for i in E['data']['pincodes']:\n",
    "                entityName = i['entityName']\n",
    "                count = i['metric']['count']\n",
    "                amount = i['metric']['amount']\n",
    "                columns4['Pincodes'].append(entityName)\n",
    "                columns4['Transaction_count'].append(count)\n",
    "                columns4['Transaction_amount'].append(amount)\n",
    "                columns4['States'].append(state)\n",
    "                columns4['Years'].append(year)\n",
    "                columns4['Quartile'].append(int(file.strip('.json')))\n",
    "                \n",
    "top_transactions = pd.DataFrame(columns4)     \n",
    "\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('andhra-pradesh','andhra pradesh')\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('madhya-pradesh','madhya pradesh')\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('west-bengal','west bengal')\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('jammu-&-kashmir','jammu & kashmir')\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('himachal-pradesh','himachal pradesh')\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('arunachal-pradesh','arunachal pradesh')\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('tamil-nadu','tamil nadu')\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('uttar-pradesh','uttar pradesh')\n",
    "\n",
    "top_transactions['States'] = top_transactions['States'].str.replace('dadra-&-nagar-haveli-&-daman-&-diu','dadra and nagar haveli and daman and diu')\n",
    "top_transactions['States'] = top_transactions['States'].str.title()             \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "path6 = 'C:/Users/Srinivasa Rao/OneDrive/Documents/PhonePe/pulse/data/top/user/country/india/state/'\n",
    "top_user_list = os.listdir(path6)\n",
    "\n",
    "\n",
    "columns5 = {'States':[], 'Years':[], 'Quartile':[], \n",
    "           'Pincodes':[], 'RegisteredUsers':[], \n",
    "           \n",
    "           }\n",
    "\n",
    "for state in top_user_list:\n",
    "    curr_states = path6 + state + '/'\n",
    "    aggre_year_list = os.listdir(curr_states)\n",
    "    \n",
    "    for year in aggre_year_list:\n",
    "        curr_year = curr_states + year + \"/\"\n",
    "        aggre_file_list = os.listdir(curr_year)\n",
    "        \n",
    "        for file in aggre_file_list:\n",
    "            curr_file = curr_year + file\n",
    "            data = open(curr_file,'r')\n",
    "            \n",
    "            F = json.load(data)\n",
    "            \n",
    "            for i in F['data']['pincodes']:\n",
    "                entityName = i['name']\n",
    "                registeredusers = i['registeredUsers']\n",
    "                columns5['Pincodes'].append(entityName)\n",
    "                columns5['RegisteredUsers'].append(registeredusers)\n",
    "                columns5['States'].append(state)\n",
    "                columns5['Years'].append(year)\n",
    "                columns5['Quartile'].append(int(file.strip('.json')))\n",
    "\n",
    "top_users = pd.DataFrame(columns5)\n",
    "\n",
    "top_users['States'] = top_users['States'].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "top_users['States'] = top_users['States'].str.replace('andhra-pradesh','andhra pradesh')\n",
    "top_users['States'] = top_users['States'].str.replace('west-bengal','west bengal')\n",
    "top_users['States'] = top_users['States'].str.replace('jammu-&-kashmir','jammu & kashmir')\n",
    "top_users['States'] = top_users['States'].str.replace(\"himachal-pradesh\",'himachal pradesh')\n",
    "top_users['States'] = top_users['States'].str.replace('arunachal-pradesh','arunachal pradesh')\n",
    "top_users['States'] = top_users['States'].str.replace('tamil-nadu','tamil nadu')\n",
    "top_users['States'] = top_users['States'].str.replace('madhya-pradesh','madhya pradesh')\n",
    "top_users['States'] = top_users['States'].str.replace('uttar-pradesh','uttar pradesh')\n",
    "\n",
    "top_users['States'] = top_users['States'].str.replace('dadra-&-nagar-haveli-&-daman-&-diu','dadra and nagar haveli and daman and diu')\n",
    "top_users['States'] = top_users['States'].str.title() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL TABLE CREATION\n",
    "\n",
    "mydb = psycopg2.connect(host = 'localhost',\n",
    "                        user = 'postgres',\n",
    "                        port = '5432',\n",
    "                        database = \"Phonepe_Data\",\n",
    "                        password = 'Space-time123')\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "create_query1 = '''CREATE TABLE if not exists aggregated_transaction(States varchar(333),\n",
    "                                                                    Years int,\n",
    "                                                                    Quartile int,\n",
    "                                                                    Transaction_type varchar(333),\n",
    "                                                                    Transaction_count bigint,\n",
    "                                                                    Transaction_amount bigint)'''\n",
    "\n",
    "cursor.execute(create_query1)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "insert_query1 = '''INSERT INTO aggregated_transaction(States, Years, Quartile,\n",
    "                                                      Transaction_type, Transaction_count, \n",
    "                                                      Transaction_amount)\n",
    "                                        \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "                                                       \n",
    "data = aggre_transaction.values.tolist()\n",
    "cursor.executemany(insert_query1, data)\n",
    "mydb.commit()\n",
    "\n",
    "create_query2 = '''CREATE TABLE if not exists aggregated_user(States varchar(333),\n",
    "                                                                    Years int,\n",
    "                                                                    Quartile int,\n",
    "                                                                    Brands varchar(333),\n",
    "                                                                    Transaction_count bigint,\n",
    "                                                                    Percentage float)'''\n",
    "\n",
    "cursor.execute(create_query2)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "insert_query2 = '''INSERT INTO aggregated_user(States, Years, Quartile,\n",
    "                                                      Brands, Transaction_count, \n",
    "                                                      Percentage)\n",
    "                                        \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "                                                       \n",
    "data = aggre_user.values.tolist()\n",
    "cursor.executemany(insert_query2, data)\n",
    "mydb.commit()\n",
    "\n",
    "\n",
    "create_query3 = '''CREATE TABLE if not exists map_transaction(States varchar(255),\n",
    "                                                                    Years int,\n",
    "                                                                    Quartile int,\n",
    "                                                                    Districts varchar(255),\n",
    "                                                                    Transaction_count bigint,\n",
    "                                                                    Transaction_amount NUMERIC)'''\n",
    "\n",
    "cursor.execute(create_query3)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query3 = '''INSERT INTO map_transaction(States, Years, Quartile,\n",
    "                                                      Districts, Transaction_count, \n",
    "                                                      Transaction_amount)\n",
    "                                        \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "                                                       \n",
    "data = map_transactions.values.tolist()\n",
    "cursor.executemany(insert_query3, data)\n",
    "mydb.commit()\n",
    "\n",
    "create_query4 = '''CREATE TABLE if not exists map_users(States varchar(333),\n",
    "                                                                    Years int,\n",
    "                                                                    Quartile int,\n",
    "                                                                    Districts varchar(333),\n",
    "                                                                    RegisteredUsers bigint,\n",
    "                                                                    AppOpens bigint)'''\n",
    "\n",
    "cursor.execute(create_query4)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query4 = '''INSERT INTO map_users(States, Years, Quartile,\n",
    "                                                      Districts, RegisteredUsers, \n",
    "                                                      AppOpens)\n",
    "                                        \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "                                                       \n",
    "data = map_user.values.tolist()\n",
    "cursor.executemany(insert_query4, data)\n",
    "mydb.commit()\n",
    "\n",
    "create_query5 = '''CREATE TABLE if not exists top_transaction(States varchar(333),\n",
    "                                                                    Years int,\n",
    "                                                                    Quartile int,\n",
    "                                                                    Pincodes int,\n",
    "                                                                    Transaction_count bigint,\n",
    "                                                                    Transaction_amount bigint)'''\n",
    "\n",
    "cursor.execute(create_query5)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query5 = '''INSERT INTO top_transaction(States, Years, Quartile,\n",
    "                                                      Pincodes, Transaction_count, \n",
    "                                                      Transaction_amount)\n",
    "                                        \n",
    "                                                       values(%s,%s,%s,%s,%s,%s)'''\n",
    "                                                       \n",
    "data = top_transactions.values.tolist()\n",
    "cursor.executemany(insert_query5, data)\n",
    "mydb.commit()\n",
    "\n",
    "create_query6 = '''CREATE TABLE if not exists top_user(States varchar(333),\n",
    "                                                                    Years int,\n",
    "                                                                    Quartile int,\n",
    "                                                                    Pincodes int,\n",
    "                                                                    RegisteredUsers bigint)'''\n",
    "\n",
    "cursor.execute(create_query6)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query6 = '''INSERT INTO top_user(States, Years, Quartile,\n",
    "                                                      Pincodes, RegisteredUsers)\n",
    "                                        \n",
    "                                                       values(%s,%s,%s,%s,%s)'''\n",
    "                                                       \n",
    "data = top_users.values.tolist()\n",
    "cursor.executemany(insert_query6, data)\n",
    "mydb.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
